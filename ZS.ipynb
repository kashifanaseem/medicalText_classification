{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3963c15d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Classification of Conversation Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58b747a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Objective:** To classify the text into two categories, for which a labelled dataset was given.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c663478e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Table of content\n",
    "1. Aim\n",
    "2. Prerequists\n",
    "3. Data gathering\n",
    "4. Data prepration\n",
    "5. Modelling\n",
    "6. Accuracy\n",
    "7. Saving test predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b4c424",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prerequists\n",
    "All the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6389c7ab",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd         \n",
    "import re                     \n",
    "import emoji          \n",
    "import contractions    \n",
    "from collections import Counter       \n",
    "\n",
    "from nltk.corpus import stopwords    \n",
    "from nltk.tokenize import WordPunctTokenizer  \n",
    "from nltk.stem import WordNetLemmatizer   \n",
    "from nltk.collocations import BigramCollocationFinder \n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer   \n",
    "from sklearn import metrics  \n",
    "from sklearn.pipeline import Pipeline  \n",
    "from sklearn.svm import SVC, LinearSVC    \n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0367acf9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data\n",
    "\n",
    "* Gathering the data\n",
    "* Printing a few records\n",
    "* Looking for missing records\n",
    "* Understanding the missing records "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ad3347d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Host</th>\n",
       "      <th>Link</th>\n",
       "      <th>Date(ET)</th>\n",
       "      <th>Time(ET)</th>\n",
       "      <th>time(GMT)</th>\n",
       "      <th>Title</th>\n",
       "      <th>TRANS_CONV_TEXT</th>\n",
       "      <th>Patient_Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FORUMS</td>\n",
       "      <td>cafepharma.com</td>\n",
       "      <td>http://cafepharma.com/boards/threads/epstein.5...</td>\n",
       "      <td>6/15/2016</td>\n",
       "      <td>13:58:00</td>\n",
       "      <td>6/15/2016 23:28</td>\n",
       "      <td>Epstein</td>\n",
       "      <td>I don't disagree with you in principle. I'm ju...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FORUMS</td>\n",
       "      <td>www.patient.co.uk</td>\n",
       "      <td>http://www.patient.co.uk/forums/discuss/enlarg...</td>\n",
       "      <td>5/7/2016</td>\n",
       "      <td>0.820833333</td>\n",
       "      <td>42498.21667</td>\n",
       "      <td>Enlarged Heart.Thread Enlarged Heart</td>\n",
       "      <td>I am always dizzy I get dizzy standing up so I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLOG</td>\n",
       "      <td>http://abcnewsradioonline.com/entertainment-news</td>\n",
       "      <td>http://abcnewsradioonline.com/entertainment-ne...</td>\n",
       "      <td>4/14/2016</td>\n",
       "      <td>15:00:38</td>\n",
       "      <td>4/15/2016 0:30</td>\n",
       "      <td>Queen Latifah Joins American Heart Association...</td>\n",
       "      <td>Axelle/Bauer-Griffin/FilmMagic(NEW YORK) -- Qu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source                                              Host  \\\n",
       "0  FORUMS                                    cafepharma.com   \n",
       "1  FORUMS                                 www.patient.co.uk   \n",
       "2    BLOG  http://abcnewsradioonline.com/entertainment-news   \n",
       "\n",
       "                                                Link   Date(ET)     Time(ET)  \\\n",
       "0  http://cafepharma.com/boards/threads/epstein.5...  6/15/2016     13:58:00   \n",
       "1  http://www.patient.co.uk/forums/discuss/enlarg...   5/7/2016  0.820833333   \n",
       "2  http://abcnewsradioonline.com/entertainment-ne...  4/14/2016     15:00:38   \n",
       "\n",
       "         time(GMT)                                              Title  \\\n",
       "0  6/15/2016 23:28                                            Epstein   \n",
       "1      42498.21667               Enlarged Heart.Thread Enlarged Heart   \n",
       "2   4/15/2016 0:30  Queen Latifah Joins American Heart Association...   \n",
       "\n",
       "                                     TRANS_CONV_TEXT  Patient_Tag  \n",
       "0  I don't disagree with you in principle. I'm ju...            0  \n",
       "1  I am always dizzy I get dizzy standing up so I...            1  \n",
       "2  Axelle/Bauer-Griffin/FilmMagic(NEW YORK) -- Qu...            0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('dataset/train.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "574c13cd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Source               0\n",
       "Host                59\n",
       "Link                 0\n",
       "Date(ET)             0\n",
       "Time(ET)             0\n",
       "time(GMT)          161\n",
       "Title              216\n",
       "TRANS_CONV_TEXT      1\n",
       "Patient_Tag          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faf1b255",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Host</th>\n",
       "      <th>Link</th>\n",
       "      <th>Date(ET)</th>\n",
       "      <th>Time(ET)</th>\n",
       "      <th>time(GMT)</th>\n",
       "      <th>Title</th>\n",
       "      <th>TRANS_CONV_TEXT</th>\n",
       "      <th>Patient_Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>FORUMS</td>\n",
       "      <td>www.reddit.com</td>\n",
       "      <td>https://www.reddit.com/r/science/comments/4ogb...</td>\n",
       "      <td>6/16/2016</td>\n",
       "      <td>19:25:00</td>\n",
       "      <td>6/17/2016 4:55</td>\n",
       "      <td>Teenage weight is linked to risk of heart fail...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Source            Host  \\\n",
       "841  FORUMS  www.reddit.com   \n",
       "\n",
       "                                                  Link   Date(ET)  Time(ET)  \\\n",
       "841  https://www.reddit.com/r/science/comments/4ogb...  6/16/2016  19:25:00   \n",
       "\n",
       "          time(GMT)                                              Title  \\\n",
       "841  6/17/2016 4:55  Teenage weight is linked to risk of heart fail...   \n",
       "\n",
       "    TRANS_CONV_TEXT  Patient_Tag  \n",
       "841             NaN            0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[(data['TRANS_CONV_TEXT'].isnull())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ddb617",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Prepration\n",
    "\n",
    "* To prepare the text for training cleaning of the text was required, which was done in few steps:\n",
    "    1. Removing emojis\n",
    "    2. Fixing contractions\n",
    "    3. Removing special characters and numbers\n",
    "    4. Creating tokens from text\n",
    "    5. Removing stopwords\n",
    "    6. Lemmatizing\n",
    "\n",
    "\n",
    "* N-grams was created\n",
    "\n",
    "\n",
    "* Combined title and the conversation text, applied cleaning and N-grams on new combined text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd65c0f5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()   #lemmatizer\n",
    "stop_words = stopwords.words('English')    #stop words from english\n",
    "stop_words.remove('not')\n",
    "stop_words.remove('no')\n",
    "\n",
    "def preprocessing(myString):\n",
    "    \"\"\"to clean the text, to remove contraction\"\"\"\n",
    "    myString = emoji.get_emoji_regexp().sub(r'', myString)  \n",
    "    string_encode = myString.encode() \n",
    "    myString = string_encode.decode()   \n",
    "    myString = contractions.fix(myString)   \n",
    "    myString = re.sub('[^a-zA-Z]', ' ',myString) \n",
    "    myString = myString.strip()\n",
    "    tokenizer = WordPunctTokenizer()   \n",
    "    tokens = tokenizer.tokenize(myString)\n",
    "    tokens = [t for t in tokens if t.lower() not in stop_words]\n",
    "    tokens = [wordnet_lemmatizer.lemmatize(x) for x in tokens ]\n",
    "    tokens = [wordnet_lemmatizer.lemmatize(x,pos='v') for x in tokens ]\n",
    "    myString=' '.join(tokens)\n",
    "    return myString\n",
    "\n",
    "def get_bigrams(myString):\n",
    "    \"\"\"To create bigrams\"\"\"\n",
    "    try:\n",
    "        tokenizer = WordPunctTokenizer()   \n",
    "        tokens = tokenizer.tokenize(myString)\n",
    "        bigram_finder = BigramCollocationFinder.from_words(tokens)\n",
    "        bigrams = bigram_finder.nbest(BigramAssocMeasures.chi_sq, 100)\n",
    "        tt=[\"%s %s\" % bigram_tuple for bigram_tuple in bigrams]\n",
    "        result = [x for x in tt ]\n",
    "    except Exception as e:\n",
    "        print(myString)\n",
    "        result=[]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79a231d8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_data(dataframe,columns,final):\n",
    "    df=dataframe[columns]\n",
    "    df.dropna(axis=0, subset=['TRANS_CONV_TEXT'], inplace=True)\n",
    "    for i,row in df.iterrows():\n",
    "        if type(row['Title'])==str:\n",
    "            df.loc[i,'New TRANS_CONV_TEXT']=row['Title']+'. '+df['TRANS_CONV_TEXT'][i]\n",
    "        else:\n",
    "            df.loc[i,'New TRANS_CONV_TEXT']=df['TRANS_CONV_TEXT'][i]\n",
    "    df=df[final]\n",
    "    df['conv'] = df['New TRANS_CONV_TEXT'].apply(lambda y:preprocessing(y))\n",
    "    df['conv_bigrams'] = df['conv'].apply(lambda y:get_bigrams(y))\n",
    "    df['conv_bigrams_'] = [\" \".join(x) for x in df['conv_bigrams']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea21ce6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Applying Data Prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1c0fb6e",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-fe6c8634d3ae>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(axis=0, subset=['TRANS_CONV_TEXT'], inplace=True)\n",
      "C:\\Users\\320148311\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1599: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = infer_fill_value(value)\n",
      "C:\\Users\\320148311\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "dftrain=prepare_data(data,['Title','TRANS_CONV_TEXT','Patient_Tag'],['New TRANS_CONV_TEXT','Patient_Tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0f8988c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>New TRANS_CONV_TEXT</th>\n",
       "      <th>Patient_Tag</th>\n",
       "      <th>conv</th>\n",
       "      <th>conv_bigrams</th>\n",
       "      <th>conv_bigrams_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Epstein. I don't disagree with you in principl...</td>\n",
       "      <td>0</td>\n",
       "      <td>Epstein not disagree principle say Entresto ma...</td>\n",
       "      <td>[David let, Diovan discover, Ignorance frequen...</td>\n",
       "      <td>David let Diovan discover Ignorance frequently...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Enlarged Heart.Thread Enlarged Heart. I am alw...</td>\n",
       "      <td>1</td>\n",
       "      <td>Enlarged Heart Thread Enlarged Heart always di...</td>\n",
       "      <td>[Christies cancer, England fantastic, Enlarged...</td>\n",
       "      <td>Christies cancer England fantastic Enlarged He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Queen Latifah Joins American Heart Association...</td>\n",
       "      <td>0</td>\n",
       "      <td>Queen Latifah Joins American Heart Association...</td>\n",
       "      <td>[ABC Radio, American Heart, Americans live, As...</td>\n",
       "      <td>ABC Radio American Heart Americans live Associ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bulaemia. I am 17 and I have been throwing up ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Bulaemia throw year almost everyday throw bloo...</td>\n",
       "      <td>[ANSWER Good, Ask school, Electrolyte imbalanc...</td>\n",
       "      <td>ANSWER Good Ask school Electrolyte imbalance F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DIY Silver interconnects and RCAs???. Quote: O...</td>\n",
       "      <td>0</td>\n",
       "      <td>DIY Silver interconnect RCAs Quote Originally ...</td>\n",
       "      <td>[Boyan Silyavski, DIY Silver, GROUNDED skip, O...</td>\n",
       "      <td>Boyan Silyavski DIY Silver GROUNDED skip Origi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 New TRANS_CONV_TEXT  Patient_Tag  \\\n",
       "0  Epstein. I don't disagree with you in principl...            0   \n",
       "1  Enlarged Heart.Thread Enlarged Heart. I am alw...            1   \n",
       "2  Queen Latifah Joins American Heart Association...            0   \n",
       "3  Bulaemia. I am 17 and I have been throwing up ...            1   \n",
       "4  DIY Silver interconnects and RCAs???. Quote: O...            0   \n",
       "\n",
       "                                                conv  \\\n",
       "0  Epstein not disagree principle say Entresto ma...   \n",
       "1  Enlarged Heart Thread Enlarged Heart always di...   \n",
       "2  Queen Latifah Joins American Heart Association...   \n",
       "3  Bulaemia throw year almost everyday throw bloo...   \n",
       "4  DIY Silver interconnect RCAs Quote Originally ...   \n",
       "\n",
       "                                        conv_bigrams  \\\n",
       "0  [David let, Diovan discover, Ignorance frequen...   \n",
       "1  [Christies cancer, England fantastic, Enlarged...   \n",
       "2  [ABC Radio, American Heart, Americans live, As...   \n",
       "3  [ANSWER Good, Ask school, Electrolyte imbalanc...   \n",
       "4  [Boyan Silyavski, DIY Silver, GROUNDED skip, O...   \n",
       "\n",
       "                                       conv_bigrams_  \n",
       "0  David let Diovan discover Ignorance frequently...  \n",
       "1  Christies cancer England fantastic Enlarged He...  \n",
       "2  ABC Radio American Heart Americans live Associ...  \n",
       "3  ANSWER Good Ask school Electrolyte imbalance F...  \n",
       "4  Boyan Silyavski DIY Silver GROUNDED skip Origi...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad2cf24",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Spliting Data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "827a4c00",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dftrain[['conv','conv_bigrams_']], dftrain['Patient_Tag'], \n",
    "                                                    test_size=0.20,\n",
    "                                                    stratify=dftrain['Patient_Tag'],\n",
    "                                                    random_state=0\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e15407",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Linear SVC Model\n",
    "\n",
    "Used TFIDF to vectorize the documents. vectorization is important to convert the text in to vectors to make it understandatble to machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "020d80a9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "preprocessing = ColumnTransformer(\n",
    "    transformers=[\n",
    "                  ('Text_features',TfidfVectorizer(ngram_range=(1,2), analyzer='word', norm='l2'),'conv_bigrams_'),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "420545a4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "LinearSVC_pipeline = Pipeline(steps=[('preprocessing', preprocessing),\n",
    "                                   ('LinearSVC', LinearSVC(class_weight='balanced',loss='hinge', max_iter=5000,C=1))\n",
    "                                  ])\n",
    "\n",
    "LinearSVC_pipeline = LinearSVC_pipeline.fit(X_train,y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae2fe64e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "acc=LinearSVC_pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "834d3f9a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9008620689655172"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043ccbda",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Accuracy of Linear SVC Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65eb345d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94       184\n",
      "           1       0.74      0.81      0.77        48\n",
      "\n",
      "    accuracy                           0.90       232\n",
      "   macro avg       0.84      0.87      0.85       232\n",
      "weighted avg       0.91      0.90      0.90       232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LinearSVC_pred = LinearSVC_pipeline.predict(X_test)\n",
    "print(metrics.classification_report(y_test,LinearSVC_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4fb29e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "127d1f78",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "datatest=pd.read_csv('dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd18688d",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()   #lemmatizer\n",
    "stop_words = stopwords.words('English')    #stop words from english\n",
    "stop_words.remove('not')\n",
    "stop_words.remove('no')\n",
    "\n",
    "def preprocessing(myString):\n",
    "    \"\"\"to clean the text, to remove contraction\"\"\"\n",
    "    myString = emoji.get_emoji_regexp().sub(r'', myString)  \n",
    "    string_encode = myString.encode() \n",
    "    myString = string_encode.decode()   \n",
    "    myString = contractions.fix(myString)   \n",
    "    myString = re.sub('[^a-zA-Z]', ' ',myString) \n",
    "    myString = myString.strip()\n",
    "    tokenizer = WordPunctTokenizer()   \n",
    "    tokens = tokenizer.tokenize(myString)\n",
    "    tokens = [t for t in tokens if t.lower() not in stop_words]\n",
    "    tokens = [wordnet_lemmatizer.lemmatize(x) for x in tokens ]\n",
    "    tokens = [wordnet_lemmatizer.lemmatize(x,pos='v') for x in tokens ]\n",
    "    myString=' '.join(tokens)\n",
    "    return myString\n",
    "\n",
    "def get_bigrams(myString):\n",
    "    \"\"\"To create bigrams\"\"\"\n",
    "    try:\n",
    "        tokenizer = WordPunctTokenizer()   \n",
    "        tokens = tokenizer.tokenize(myString)\n",
    "        bigram_finder = BigramCollocationFinder.from_words(tokens)\n",
    "        bigrams = bigram_finder.nbest(BigramAssocMeasures.chi_sq, 100)\n",
    "        tt=[\"%s %s\" % bigram_tuple for bigram_tuple in bigrams]\n",
    "        result = [x for x in tt ]\n",
    "    except Exception as e:\n",
    "        print(myString)\n",
    "        result=[]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65ac591e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_data(dataframe,columns,final):\n",
    "    df=dataframe[columns]\n",
    "    df.dropna(axis=0, subset=['TRANS_CONV_TEXT'], inplace=True)\n",
    "    for i,row in df.iterrows():\n",
    "        if type(row['Title'])==str:\n",
    "            df.loc[i,'New TRANS_CONV_TEXT']=row['Title']+'. '+df['TRANS_CONV_TEXT'][i]\n",
    "        else:\n",
    "            df.loc[i,'New TRANS_CONV_TEXT']=df['TRANS_CONV_TEXT'][i]\n",
    "    df=df[final]\n",
    "    df['conv'] = df['New TRANS_CONV_TEXT'].apply(lambda y:preprocessing(y))\n",
    "    df['conv_bigrams'] = df['conv'].apply(lambda y:get_bigrams(y))\n",
    "    df['conv_bigrams_'] = [\" \".join(x) for x in df['conv_bigrams']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c94c8b2a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-fe6c8634d3ae>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(axis=0, subset=['TRANS_CONV_TEXT'], inplace=True)\n",
      "C:\\Users\\320148311\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1599: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = infer_fill_value(value)\n",
      "C:\\Users\\320148311\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "dftest=prepare_data(datatest,['Index','Title','TRANS_CONV_TEXT'],['Index','New TRANS_CONV_TEXT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5129d66",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Predicting and saving predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9ba7a29",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "X_result=dftest[['conv','conv_bigrams_']]\n",
    "LinearSVC_model=LinearSVC_pipeline\n",
    "SVC_pred_class = LinearSVC_model.predict(X_result)\n",
    "dftest['Patient_Tag']=SVC_pred_class\n",
    "testFile=dftest[['Index','Patient_Tag']]\n",
    "testFile.to_csv('final.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a062c8a6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Patient_Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index  Patient_Tag\n",
       "0      1            0\n",
       "1      2            1\n",
       "2      3            0\n",
       "3      4            1\n",
       "4      5            0\n",
       "5      6            0\n",
       "6      7            0\n",
       "7      8            1\n",
       "8      9            0\n",
       "9     10            0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFile.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22a26746",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Patient_Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>567</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>568</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>569</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>570</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Index  Patient_Tag\n",
       "566    567            0\n",
       "567    568            0\n",
       "568    569            0\n",
       "569    570            1\n",
       "570    571            1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFile.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719dc81a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data For transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2e79438",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.data import Sentence\n",
    "from flair.datasets import CSVClassificationCorpus\n",
    "from flair.embeddings import TransformerDocumentEmbeddings\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings\n",
    "from torch.optim.adam import Adam\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import OneCycleLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a2187e4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(924, 2) (47, 3) (185, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-0d40824fd33f>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_t['Patient_Tag'] = y_test_t\n",
      "<ipython-input-23-0d40824fd33f>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val_t['Patient_Tag'] = y_val_t\n"
     ]
    }
   ],
   "source": [
    "X_val_t, X_test_t, y_val_t, y_test_t = train_test_split(X_test, y_test, \n",
    "                                                test_size=0.20,\n",
    "                                                random_state=0)\n",
    "X_train_t=X_train[['conv']].copy()\n",
    "y_train_t=y_train.copy()\n",
    "X_train_t['Patient_Tag'] = y_train_t\n",
    "X_test_t['Patient_Tag'] = y_test_t\n",
    "X_val_t['Patient_Tag'] = y_val_t\n",
    "print(X_train_t.shape,X_test_t.shape,X_val_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "634ec718",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X_train_t[['conv','Patient_Tag']].to_csv('Training_data_zs/train.csv',index=False)\n",
    "X_test_t[['conv','Patient_Tag']].to_csv('Training_data_zs/test.csv',index=False)\n",
    "X_val_t[['conv','Patient_Tag']].to_csv('Training_data_zs/dev.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5b7f44",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Tranformers Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d2c86d1",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501305a8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Data prepration for transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dbf705e2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-19 21:40:32,350 Reading data from Training_data_zs\n",
      "2021-12-19 21:40:32,352 Train: Training_data_zs\\train.csv\n",
      "2021-12-19 21:40:32,353 Dev: Training_data_zs\\dev.csv\n",
      "2021-12-19 21:40:32,354 Test: Training_data_zs\\test.csv\n"
     ]
    }
   ],
   "source": [
    "from flair.trainers import ModelTrainer\n",
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = './Training_data_zs'\n",
    "\n",
    "# column format indicating which columns hold the text and label(s)\n",
    "column_name_map = {0: \"text\", 1: \"label_topic\"}\n",
    "\n",
    "label_type='Patient_Tag'\n",
    "# load corpus containing training, test and dev data and if CSV has a header, you can skip it\n",
    "corpus: Corpus = CSVClassificationCorpus(data_folder,\n",
    "                                         column_name_map,\n",
    "                                         skip_header=True,\n",
    "                                         delimiter=',',\n",
    "                                         label_type=label_type) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7942205d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-19 21:40:33,713 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 924/924 [00:07<00:00, 116.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-19 21:42:49,841 Corpus contains the labels: Patient_Tag (#924)\n",
      "2021-12-19 21:42:49,842 Created (for label 'Patient_Tag') Dictionary with 2 tags: 0, 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. create the label dictionary\n",
    "label_dict = corpus.make_label_dictionary(label_type=label_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1bd8d2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bdc55717",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 3. initialize transformer document embeddings (many models are available)\n",
    "flair.device = torch.device('cpu')\n",
    "document_embeddings = TransformerDocumentEmbeddings('bert-base-uncased', fine_tune=True)\n",
    "\n",
    "# 4. create the text classifier\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict,label_type=label_type)\n",
    "\n",
    "# 5. initialize the text classifier trainer with Adam optimizer\n",
    "trainer = ModelTrainer(classifier, corpus, optimizer=torch.optim.AdamW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6ecd7a4",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-14 13:48:21,806 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 13:48:21,809 Model: \"TextClassifier(\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (document_embeddings): TransformerDocumentEmbeddings(\n",
      "    (model): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-14 13:48:21,812 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 13:48:21,812 Corpus: \"Corpus: 924 train + 185 dev + 47 test sentences\"\n",
      "2021-12-14 13:48:21,813 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 13:48:21,814 Parameters:\n",
      "2021-12-14 13:48:21,816  - learning_rate: \"3e-05\"\n",
      "2021-12-14 13:48:21,817  - mini_batch_size: \"16\"\n",
      "2021-12-14 13:48:21,817  - patience: \"3\"\n",
      "2021-12-14 13:48:21,818  - anneal_factor: \"0.5\"\n",
      "2021-12-14 13:48:21,820  - max_epochs: \"5\"\n",
      "2021-12-14 13:48:21,821  - shuffle: \"True\"\n",
      "2021-12-14 13:48:21,821  - train_with_dev: \"False\"\n",
      "2021-12-14 13:48:21,822  - batch_growth_annealing: \"False\"\n",
      "2021-12-14 13:48:21,823 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 13:48:21,823 Model training base path: \"resources_BERT\\taggers\\trec\"\n",
      "2021-12-14 13:48:21,824 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 13:48:21,825 Device: cpu\n",
      "2021-12-14 13:48:21,825 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 13:48:21,826 Embeddings storage mode: none\n",
      "2021-12-14 13:48:21,833 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 13:53:16,224 epoch 1 - iter 5/58 - loss 0.14524077 - samples/sec: 0.32 - lr: 0.000030\n",
      "2021-12-14 13:56:24,775 epoch 1 - iter 10/58 - loss 0.13164646 - samples/sec: 0.42 - lr: 0.000030\n",
      "2021-12-14 14:00:19,120 epoch 1 - iter 15/58 - loss 0.12373139 - samples/sec: 0.34 - lr: 0.000030\n",
      "2021-12-14 14:04:01,285 epoch 1 - iter 20/58 - loss 0.11767574 - samples/sec: 0.36 - lr: 0.000030\n",
      "2021-12-14 14:07:45,372 epoch 1 - iter 25/58 - loss 0.11215800 - samples/sec: 0.36 - lr: 0.000029\n",
      "2021-12-14 14:11:45,071 epoch 1 - iter 30/58 - loss 0.11082756 - samples/sec: 0.33 - lr: 0.000029\n",
      "2021-12-14 14:15:53,275 epoch 1 - iter 35/58 - loss 0.10769832 - samples/sec: 0.32 - lr: 0.000029\n",
      "2021-12-14 14:19:58,939 epoch 1 - iter 40/58 - loss 0.10441063 - samples/sec: 0.33 - lr: 0.000029\n",
      "2021-12-14 14:24:31,272 epoch 1 - iter 45/58 - loss 0.10121599 - samples/sec: 0.30 - lr: 0.000028\n",
      "2021-12-14 14:29:53,423 epoch 1 - iter 50/58 - loss 0.09843859 - samples/sec: 0.25 - lr: 0.000028\n",
      "2021-12-14 14:34:37,478 epoch 1 - iter 55/58 - loss 0.09598073 - samples/sec: 0.28 - lr: 0.000027\n",
      "2021-12-14 14:37:44,006 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 14:37:44,037 EPOCH 1 done: loss 0.0939 - lr 0.0000270\n",
      "2021-12-14 14:42:34,446 DEV : loss 0.07780168950557709 - f1-score (micro avg)  0.8324\n",
      "2021-12-14 14:42:36,656 BAD EPOCHS (no improvement): 4\n",
      "2021-12-14 14:42:36,656 saving best model\n",
      "2021-12-14 14:42:37,526 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 14:48:58,412 epoch 2 - iter 5/58 - loss 0.06702887 - samples/sec: 0.24 - lr: 0.000027\n",
      "2021-12-14 14:53:18,612 epoch 2 - iter 10/58 - loss 0.05372950 - samples/sec: 0.31 - lr: 0.000026\n",
      "2021-12-14 14:57:55,072 epoch 2 - iter 15/58 - loss 0.05611186 - samples/sec: 0.29 - lr: 0.000025\n",
      "2021-12-14 15:02:52,026 epoch 2 - iter 20/58 - loss 0.05826884 - samples/sec: 0.27 - lr: 0.000025\n",
      "2021-12-14 15:07:48,400 epoch 2 - iter 25/58 - loss 0.05565549 - samples/sec: 0.27 - lr: 0.000024\n",
      "2021-12-14 15:12:05,156 epoch 2 - iter 30/58 - loss 0.05241331 - samples/sec: 0.31 - lr: 0.000024\n",
      "2021-12-14 15:15:46,310 epoch 2 - iter 35/58 - loss 0.05003991 - samples/sec: 0.36 - lr: 0.000023\n",
      "2021-12-14 15:20:03,249 epoch 2 - iter 40/58 - loss 0.05065351 - samples/sec: 0.31 - lr: 0.000022\n",
      "2021-12-14 15:23:49,559 epoch 2 - iter 45/58 - loss 0.05421854 - samples/sec: 0.36 - lr: 0.000021\n",
      "2021-12-14 15:27:51,387 epoch 2 - iter 50/58 - loss 0.05257515 - samples/sec: 0.33 - lr: 0.000021\n",
      "2021-12-14 15:32:14,462 epoch 2 - iter 55/58 - loss 0.05177560 - samples/sec: 0.30 - lr: 0.000020\n",
      "2021-12-14 15:35:02,182 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 15:35:02,182 EPOCH 2 done: loss 0.0518 - lr 0.0000195\n",
      "2021-12-14 15:39:40,303 DEV : loss 0.06850001215934753 - f1-score (micro avg)  0.8541\n",
      "2021-12-14 15:39:40,975 BAD EPOCHS (no improvement): 4\n",
      "2021-12-14 15:39:40,983 saving best model\n",
      "2021-12-14 15:39:41,842 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 15:44:53,056 epoch 3 - iter 5/58 - loss 0.02799744 - samples/sec: 0.31 - lr: 0.000019\n",
      "2021-12-14 15:49:54,041 epoch 3 - iter 10/58 - loss 0.02432438 - samples/sec: 0.27 - lr: 0.000018\n",
      "2021-12-14 15:54:18,535 epoch 3 - iter 15/58 - loss 0.02750315 - samples/sec: 0.30 - lr: 0.000017\n",
      "2021-12-14 15:58:39,583 epoch 3 - iter 20/58 - loss 0.02106414 - samples/sec: 0.31 - lr: 0.000016\n",
      "2021-12-14 16:03:13,828 epoch 3 - iter 25/58 - loss 0.02128226 - samples/sec: 0.29 - lr: 0.000015\n",
      "2021-12-14 16:07:44,092 epoch 3 - iter 30/58 - loss 0.02643002 - samples/sec: 0.30 - lr: 0.000015\n",
      "2021-12-14 16:12:02,459 epoch 3 - iter 35/58 - loss 0.02665889 - samples/sec: 0.31 - lr: 0.000014\n",
      "2021-12-14 16:16:31,351 epoch 3 - iter 40/58 - loss 0.02803340 - samples/sec: 0.30 - lr: 0.000013\n",
      "2021-12-14 16:21:16,370 epoch 3 - iter 45/58 - loss 0.02963538 - samples/sec: 0.28 - lr: 0.000012\n",
      "2021-12-14 16:27:17,660 epoch 3 - iter 50/58 - loss 0.02884187 - samples/sec: 0.22 - lr: 0.000011\n",
      "2021-12-14 16:33:53,297 epoch 3 - iter 55/58 - loss 0.02839308 - samples/sec: 0.20 - lr: 0.000011\n",
      "2021-12-14 16:37:23,782 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 16:37:23,830 EPOCH 3 done: loss 0.0275 - lr 0.0000102\n",
      "2021-12-14 16:45:09,421 DEV : loss 0.08334198594093323 - f1-score (micro avg)  0.8865\n",
      "2021-12-14 16:45:10,551 BAD EPOCHS (no improvement): 4\n",
      "2021-12-14 16:45:10,562 saving best model\n",
      "2021-12-14 16:45:11,819 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 16:52:22,394 epoch 4 - iter 5/58 - loss 0.00881309 - samples/sec: 0.25 - lr: 0.000009\n",
      "2021-12-14 16:57:34,001 epoch 4 - iter 10/58 - loss 0.00742773 - samples/sec: 0.26 - lr: 0.000009\n",
      "2021-12-14 17:03:53,051 epoch 4 - iter 15/58 - loss 0.00515789 - samples/sec: 0.21 - lr: 0.000008\n",
      "2021-12-14 17:10:10,581 epoch 4 - iter 20/58 - loss 0.00742777 - samples/sec: 0.21 - lr: 0.000007\n",
      "2021-12-14 17:16:20,690 epoch 4 - iter 25/58 - loss 0.00651444 - samples/sec: 0.22 - lr: 0.000007\n",
      "2021-12-14 17:21:49,743 epoch 4 - iter 30/58 - loss 0.01151639 - samples/sec: 0.24 - lr: 0.000006\n",
      "2021-12-14 17:27:40,162 epoch 4 - iter 35/58 - loss 0.01511540 - samples/sec: 0.23 - lr: 0.000005\n",
      "2021-12-14 17:33:33,474 epoch 4 - iter 40/58 - loss 0.01498387 - samples/sec: 0.23 - lr: 0.000005\n",
      "2021-12-14 17:40:19,690 epoch 4 - iter 45/58 - loss 0.01361021 - samples/sec: 0.20 - lr: 0.000004\n",
      "2021-12-14 17:45:47,269 epoch 4 - iter 50/58 - loss 0.01368970 - samples/sec: 0.24 - lr: 0.000004\n",
      "2021-12-14 17:51:09,665 epoch 4 - iter 55/58 - loss 0.01323352 - samples/sec: 0.25 - lr: 0.000003\n",
      "2021-12-14 17:54:08,444 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 17:54:08,488 EPOCH 4 done: loss 0.0135 - lr 0.0000028\n",
      "2021-12-14 18:01:46,873 DEV : loss 0.10853151977062225 - f1-score (micro avg)  0.8973\n",
      "2021-12-14 18:01:48,045 BAD EPOCHS (no improvement): 4\n",
      "2021-12-14 18:01:48,054 saving best model\n",
      "2021-12-14 18:01:49,357 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 18:10:13,375 epoch 5 - iter 5/58 - loss 0.00061942 - samples/sec: 0.20 - lr: 0.000002\n",
      "2021-12-14 18:17:18,644 epoch 5 - iter 10/58 - loss 0.00440996 - samples/sec: 0.19 - lr: 0.000002\n",
      "2021-12-14 18:24:07,353 epoch 5 - iter 15/58 - loss 0.00517084 - samples/sec: 0.20 - lr: 0.000002\n",
      "2021-12-14 18:29:17,851 epoch 5 - iter 20/58 - loss 0.00600663 - samples/sec: 0.26 - lr: 0.000001\n",
      "2021-12-14 19:02:18,891 epoch 5 - iter 25/58 - loss 0.00571533 - samples/sec: 0.04 - lr: 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-14 19:06:51,726 epoch 5 - iter 30/58 - loss 0.00483408 - samples/sec: 0.29 - lr: 0.000001\n",
      "2021-12-14 19:10:37,645 epoch 5 - iter 35/58 - loss 0.00423217 - samples/sec: 0.35 - lr: 0.000000\n",
      "2021-12-14 19:14:42,077 epoch 5 - iter 40/58 - loss 0.00433103 - samples/sec: 0.33 - lr: 0.000000\n",
      "2021-12-14 19:18:32,803 epoch 5 - iter 45/58 - loss 0.00402068 - samples/sec: 0.35 - lr: 0.000000\n",
      "2021-12-14 19:22:31,889 epoch 5 - iter 50/58 - loss 0.00382390 - samples/sec: 0.33 - lr: 0.000000\n",
      "2021-12-14 19:26:30,623 epoch 5 - iter 55/58 - loss 0.00377895 - samples/sec: 0.34 - lr: 0.000000\n",
      "2021-12-14 19:28:51,329 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 19:28:51,376 EPOCH 5 done: loss 0.0037 - lr 0.0000000\n",
      "2021-12-14 19:32:57,654 DEV : loss 0.11610954999923706 - f1-score (micro avg)  0.8919\n",
      "2021-12-14 19:32:58,138 BAD EPOCHS (no improvement): 4\n",
      "2021-12-14 19:32:59,170 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 19:32:59,170 loading file resources_BERT\\taggers\\trec\\best-model.pt\n",
      "2021-12-14 19:34:19,177 0.8936\t0.8936\t0.8936\t0.8936\n",
      "2021-12-14 19:34:19,177 \n",
      "Results:\n",
      "- F-score (micro) 0.8936\n",
      "- F-score (macro) 0.8017\n",
      "- Accuracy 0.8936\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9024    0.9737    0.9367        38\n",
      "           1     0.8333    0.5556    0.6667         9\n",
      "\n",
      "   micro avg     0.8936    0.8936    0.8936        47\n",
      "   macro avg     0.8679    0.7646    0.8017        47\n",
      "weighted avg     0.8892    0.8936    0.8850        47\n",
      " samples avg     0.8936    0.8936    0.8936        47\n",
      "\n",
      "2021-12-14 19:34:19,177 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.8936170212765957,\n",
       " 'dev_score_history': [0.8324324324324325,\n",
       "  0.854054054054054,\n",
       "  0.8864864864864865,\n",
       "  0.8972972972972972,\n",
       "  0.8918918918918919],\n",
       " 'train_loss_history': [0.09392895966813496,\n",
       "  0.051846714226012884,\n",
       "  0.02748573507872437,\n",
       "  0.013488688543841698,\n",
       "  0.0037132242208883165],\n",
       " 'dev_loss_history': [tensor(0.0778),\n",
       "  tensor(0.0685),\n",
       "  tensor(0.0833),\n",
       "  tensor(0.1085),\n",
       "  tensor(0.1161)]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train('resources_BERT/taggers/trec',\n",
    "               learning_rate=3e-5, # use very small learning rate\n",
    "               mini_batch_size=16,\n",
    "               mini_batch_chunk_size=4, # optionally set this if transformer is too much for your machine\n",
    "               max_epochs=5, # terminate after 5 epochs\n",
    "               scheduler=OneCycleLR,\n",
    "               embeddings_storage_mode='none',\n",
    "               weight_decay=0.,\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d5671f",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### 4. distilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bd674d25",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# # 3. initialize transformer document embeddings (many models are available)\n",
    "# document_embeddings = TransformerDocumentEmbeddings('distilbert-base-uncased', fine_tune=True)\n",
    "# # flair.device = torch.device('cpu')\n",
    "# # 4. create the text classifier\n",
    "# classifier = TextClassifier(document_embeddings, label_dictionary=label_dict,label_type=label_type)\n",
    "\n",
    "# # 5. initialize the text classifier trainer with Adam optimizer\n",
    "# trainer = ModelTrainer(classifier, corpus, optimizer=Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "988f00f6",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# # 6. start the training\n",
    "# trainer.train('resources_distilbert/taggers/trec',\n",
    "#               learning_rate=3e-5, # use very small learning rate\n",
    "#               mini_batch_size=16,\n",
    "#               mini_batch_chunk_size=4, # optionally set this if transformer is too much for your machine\n",
    "#               max_epochs=5, # terminate after 5 epochs .86\n",
    "#               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34736be4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5. Al bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21f8e49f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# 3. initialize transformer document embeddings (many models are available)\n",
    "#flair.device = torch.device('cpu')\n",
    "document_embeddings = TransformerDocumentEmbeddings('albert-base-v1', fine_tune=True)\n",
    "\n",
    "# 4. create the text classifier\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict,label_type=label_type)\n",
    "\n",
    "# 5. initialize the text classifier trainer with Adam optimizer\n",
    "trainer = ModelTrainer(classifier, corpus, optimizer=torch.optim.AdamW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a684fbe",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-14 19:36:17,098 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 19:36:17,100 Model: \"TextClassifier(\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (document_embeddings): TransformerDocumentEmbeddings(\n",
      "    (model): AlbertModel(\n",
      "      (embeddings): AlbertEmbeddings(\n",
      "        (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 128)\n",
      "        (token_type_embeddings): Embedding(2, 128)\n",
      "        (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): AlbertTransformer(\n",
      "        (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
      "        (albert_layer_groups): ModuleList(\n",
      "          (0): AlbertLayerGroup(\n",
      "            (albert_layers): ModuleList(\n",
      "              (0): AlbertLayer(\n",
      "                (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (attention): AlbertAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (attention_dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                )\n",
      "                (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (pooler_activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2021-12-14 19:36:17,100 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 19:36:17,100 Corpus: \"Corpus: 924 train + 185 dev + 47 test sentences\"\n",
      "2021-12-14 19:36:17,100 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 19:36:17,105 Parameters:\n",
      "2021-12-14 19:36:17,105  - learning_rate: \"3e-05\"\n",
      "2021-12-14 19:36:17,105  - mini_batch_size: \"16\"\n",
      "2021-12-14 19:36:17,105  - patience: \"3\"\n",
      "2021-12-14 19:36:17,105  - anneal_factor: \"0.5\"\n",
      "2021-12-14 19:36:17,105  - max_epochs: \"5\"\n",
      "2021-12-14 19:36:17,112  - shuffle: \"True\"\n",
      "2021-12-14 19:36:17,114  - train_with_dev: \"False\"\n",
      "2021-12-14 19:36:17,114  - batch_growth_annealing: \"False\"\n",
      "2021-12-14 19:36:17,115 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 19:36:17,116 Model training base path: \"resources_albert\\taggers\\trec\"\n",
      "2021-12-14 19:36:17,117 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 19:36:17,118 Device: cpu\n",
      "2021-12-14 19:36:17,119 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 19:36:17,120 Embeddings storage mode: none\n",
      "2021-12-14 19:36:17,126 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 19:40:55,188 epoch 1 - iter 5/58 - loss 0.18495574 - samples/sec: 0.34 - lr: 0.000030\n",
      "2021-12-14 19:43:49,545 epoch 1 - iter 10/58 - loss 0.15157416 - samples/sec: 0.47 - lr: 0.000030\n",
      "2021-12-14 19:47:28,260 epoch 1 - iter 15/58 - loss 0.13402040 - samples/sec: 0.37 - lr: 0.000030\n",
      "2021-12-14 19:50:44,196 epoch 1 - iter 20/58 - loss 0.12456796 - samples/sec: 0.41 - lr: 0.000030\n",
      "2021-12-14 19:53:47,342 epoch 1 - iter 25/58 - loss 0.11404517 - samples/sec: 0.44 - lr: 0.000029\n",
      "2021-12-14 19:56:56,410 epoch 1 - iter 30/58 - loss 0.11108982 - samples/sec: 0.42 - lr: 0.000029\n",
      "2021-12-14 20:00:27,930 epoch 1 - iter 35/58 - loss 0.10679843 - samples/sec: 0.38 - lr: 0.000029\n",
      "2021-12-14 20:03:26,340 epoch 1 - iter 40/58 - loss 0.10280284 - samples/sec: 0.45 - lr: 0.000029\n",
      "2021-12-14 20:07:27,502 epoch 1 - iter 45/58 - loss 0.10071878 - samples/sec: 0.33 - lr: 0.000028\n",
      "2021-12-14 20:11:09,184 epoch 1 - iter 50/58 - loss 0.09791774 - samples/sec: 0.36 - lr: 0.000028\n",
      "2021-12-14 20:14:39,921 epoch 1 - iter 55/58 - loss 0.09612243 - samples/sec: 0.38 - lr: 0.000027\n",
      "2021-12-14 20:17:25,673 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 20:17:25,689 EPOCH 1 done: loss 0.0946 - lr 0.0000270\n",
      "2021-12-14 20:21:29,184 DEV : loss 0.07162979990243912 - f1-score (micro avg)  0.8378\n",
      "2021-12-14 20:21:29,660 BAD EPOCHS (no improvement): 4\n",
      "2021-12-14 20:21:29,665 saving best model\n",
      "2021-12-14 20:21:29,745 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 20:25:57,401 epoch 2 - iter 5/58 - loss 0.05074954 - samples/sec: 0.35 - lr: 0.000027\n",
      "2021-12-14 20:29:11,393 epoch 2 - iter 10/58 - loss 0.09121933 - samples/sec: 0.42 - lr: 0.000026\n",
      "2021-12-14 20:32:41,168 epoch 2 - iter 15/58 - loss 0.08210146 - samples/sec: 0.38 - lr: 0.000025\n",
      "2021-12-14 20:35:49,991 epoch 2 - iter 20/58 - loss 0.08822211 - samples/sec: 0.42 - lr: 0.000025\n",
      "2021-12-14 20:39:01,333 epoch 2 - iter 25/58 - loss 0.08716320 - samples/sec: 0.42 - lr: 0.000024\n",
      "2021-12-14 20:42:32,828 epoch 2 - iter 30/58 - loss 0.08009156 - samples/sec: 0.38 - lr: 0.000024\n",
      "2021-12-14 20:46:33,026 epoch 2 - iter 35/58 - loss 0.07903784 - samples/sec: 0.34 - lr: 0.000023\n",
      "2021-12-14 20:50:10,512 epoch 2 - iter 40/58 - loss 0.08052829 - samples/sec: 0.37 - lr: 0.000022\n",
      "2021-12-14 20:54:03,598 epoch 2 - iter 45/58 - loss 0.07768153 - samples/sec: 0.34 - lr: 0.000021\n",
      "2021-12-14 20:57:47,275 epoch 2 - iter 50/58 - loss 0.07305744 - samples/sec: 0.36 - lr: 0.000021\n",
      "2021-12-14 21:01:42,556 epoch 2 - iter 55/58 - loss 0.07322875 - samples/sec: 0.34 - lr: 0.000020\n",
      "2021-12-14 21:04:03,787 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 21:04:03,787 EPOCH 2 done: loss 0.0709 - lr 0.0000195\n",
      "2021-12-14 21:08:16,617 DEV : loss 0.09394481778144836 - f1-score (micro avg)  0.8162\n",
      "2021-12-14 21:08:17,065 BAD EPOCHS (no improvement): 4\n",
      "2021-12-14 21:08:17,071 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 21:12:56,358 epoch 3 - iter 5/58 - loss 0.04620081 - samples/sec: 0.33 - lr: 0.000019\n",
      "2021-12-14 21:16:33,621 epoch 3 - iter 10/58 - loss 0.04635330 - samples/sec: 0.37 - lr: 0.000018\n",
      "2021-12-14 21:19:44,673 epoch 3 - iter 15/58 - loss 0.03542141 - samples/sec: 0.42 - lr: 0.000017\n",
      "2021-12-14 21:23:29,207 epoch 3 - iter 20/58 - loss 0.03396884 - samples/sec: 0.36 - lr: 0.000016\n",
      "2021-12-14 21:26:27,851 epoch 3 - iter 25/58 - loss 0.03944654 - samples/sec: 0.45 - lr: 0.000015\n",
      "2021-12-14 21:29:50,954 epoch 3 - iter 30/58 - loss 0.04395863 - samples/sec: 0.39 - lr: 0.000015\n",
      "2021-12-14 21:33:19,365 epoch 3 - iter 35/58 - loss 0.04826900 - samples/sec: 0.38 - lr: 0.000014\n",
      "2021-12-14 21:36:31,768 epoch 3 - iter 40/58 - loss 0.04765929 - samples/sec: 0.42 - lr: 0.000013\n",
      "2021-12-14 21:39:41,529 epoch 3 - iter 45/58 - loss 0.04540067 - samples/sec: 0.42 - lr: 0.000012\n",
      "2021-12-14 21:42:43,831 epoch 3 - iter 50/58 - loss 0.04606933 - samples/sec: 0.44 - lr: 0.000011\n",
      "2021-12-14 21:46:40,215 epoch 3 - iter 55/58 - loss 0.04605257 - samples/sec: 0.34 - lr: 0.000011\n",
      "2021-12-14 21:48:37,309 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 21:48:37,309 EPOCH 3 done: loss 0.0446 - lr 0.0000102\n",
      "2021-12-14 21:52:46,679 DEV : loss 0.06955612450838089 - f1-score (micro avg)  0.8595\n",
      "2021-12-14 21:52:47,096 BAD EPOCHS (no improvement): 4\n",
      "2021-12-14 21:52:47,108 saving best model\n",
      "2021-12-14 21:52:47,160 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-14 21:57:13,276 epoch 4 - iter 5/58 - loss 0.04045948 - samples/sec: 0.36 - lr: 0.000009\n",
      "2021-12-14 22:00:43,566 epoch 4 - iter 10/58 - loss 0.03100806 - samples/sec: 0.38 - lr: 0.000009\n",
      "2021-12-14 22:04:15,442 epoch 4 - iter 15/58 - loss 0.02406540 - samples/sec: 0.38 - lr: 0.000008\n",
      "2021-12-14 22:07:38,166 epoch 4 - iter 20/58 - loss 0.02504253 - samples/sec: 0.39 - lr: 0.000007\n",
      "2021-12-14 22:10:26,488 epoch 4 - iter 25/58 - loss 0.02396558 - samples/sec: 0.48 - lr: 0.000007\n",
      "2021-12-14 22:14:22,159 epoch 4 - iter 30/58 - loss 0.02305727 - samples/sec: 0.34 - lr: 0.000006\n",
      "2021-12-14 22:18:31,982 epoch 4 - iter 35/58 - loss 0.02294940 - samples/sec: 0.32 - lr: 0.000005\n",
      "2021-12-14 22:21:59,961 epoch 4 - iter 40/58 - loss 0.02223650 - samples/sec: 0.38 - lr: 0.000005\n",
      "2021-12-14 22:25:04,160 epoch 4 - iter 45/58 - loss 0.02322185 - samples/sec: 0.43 - lr: 0.000004\n",
      "2021-12-14 22:28:58,048 epoch 4 - iter 50/58 - loss 0.02333909 - samples/sec: 0.34 - lr: 0.000004\n",
      "2021-12-14 22:32:24,690 epoch 4 - iter 55/58 - loss 0.02493061 - samples/sec: 0.39 - lr: 0.000003\n",
      "2021-12-14 22:34:25,653 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 22:34:25,653 EPOCH 4 done: loss 0.0254 - lr 0.0000028\n",
      "2021-12-14 22:38:29,773 DEV : loss 0.09571314603090286 - f1-score (micro avg)  0.8649\n",
      "2021-12-14 22:38:30,201 BAD EPOCHS (no improvement): 4\n",
      "2021-12-14 22:38:30,212 saving best model\n",
      "2021-12-14 22:38:30,283 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 22:42:57,855 epoch 5 - iter 5/58 - loss 0.02130177 - samples/sec: 0.35 - lr: 0.000002\n",
      "2021-12-14 22:46:51,664 epoch 5 - iter 10/58 - loss 0.03446701 - samples/sec: 0.35 - lr: 0.000002\n",
      "2021-12-14 22:50:08,771 epoch 5 - iter 15/58 - loss 0.02698726 - samples/sec: 0.41 - lr: 0.000002\n",
      "2021-12-14 22:53:36,414 epoch 5 - iter 20/58 - loss 0.02278690 - samples/sec: 0.39 - lr: 0.000001\n",
      "2021-12-14 22:57:02,096 epoch 5 - iter 25/58 - loss 0.02048841 - samples/sec: 0.39 - lr: 0.000001\n",
      "2021-12-14 23:00:53,792 epoch 5 - iter 30/58 - loss 0.02024576 - samples/sec: 0.35 - lr: 0.000001\n",
      "2021-12-14 23:05:09,165 epoch 5 - iter 35/58 - loss 0.02058937 - samples/sec: 0.31 - lr: 0.000000\n",
      "2021-12-14 23:09:14,651 epoch 5 - iter 40/58 - loss 0.01969676 - samples/sec: 0.33 - lr: 0.000000\n",
      "2021-12-14 23:12:56,800 epoch 5 - iter 45/58 - loss 0.01851532 - samples/sec: 0.36 - lr: 0.000000\n",
      "2021-12-14 23:16:53,481 epoch 5 - iter 50/58 - loss 0.01786840 - samples/sec: 0.34 - lr: 0.000000\n",
      "2021-12-14 23:20:52,305 epoch 5 - iter 55/58 - loss 0.01696460 - samples/sec: 0.34 - lr: 0.000000\n",
      "2021-12-14 23:23:08,186 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 23:23:08,186 EPOCH 5 done: loss 0.0179 - lr 0.0000000\n",
      "2021-12-14 23:27:29,959 DEV : loss 0.084605373442173 - f1-score (micro avg)  0.8649\n",
      "2021-12-14 23:27:30,427 BAD EPOCHS (no improvement): 4\n",
      "2021-12-14 23:27:30,515 ----------------------------------------------------------------------------------------------------\n",
      "2021-12-14 23:27:30,520 loading file resources_albert\\taggers\\trec\\best-model.pt\n",
      "2021-12-14 23:28:54,786 0.8723\t0.8723\t0.8723\t0.8723\n",
      "2021-12-14 23:28:54,786 \n",
      "Results:\n",
      "- F-score (micro) 0.8723\n",
      "- F-score (macro) 0.774\n",
      "- Accuracy 0.8723\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9000    0.9474    0.9231        38\n",
      "           1     0.7143    0.5556    0.6250         9\n",
      "\n",
      "   micro avg     0.8723    0.8723    0.8723        47\n",
      "   macro avg     0.8071    0.7515    0.7740        47\n",
      "weighted avg     0.8644    0.8723    0.8660        47\n",
      " samples avg     0.8723    0.8723    0.8723        47\n",
      "\n",
      "2021-12-14 23:28:54,788 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.8723404255319149,\n",
       " 'dev_score_history': [0.8378378378378378,\n",
       "  0.8162162162162163,\n",
       "  0.8594594594594595,\n",
       "  0.8648648648648649,\n",
       "  0.8648648648648649],\n",
       " 'train_loss_history': [0.0946300085152709,\n",
       "  0.07088000135398868,\n",
       "  0.04455240070959232,\n",
       "  0.025354302336763716,\n",
       "  0.017925507204830417],\n",
       " 'dev_loss_history': [tensor(0.0716),\n",
       "  tensor(0.0939),\n",
       "  tensor(0.0696),\n",
       "  tensor(0.0957),\n",
       "  tensor(0.0846)]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. start the training\n",
    "trainer.train('resources_albert/taggers/trec',\n",
    "               learning_rate=3e-5, # use very small learning rate\n",
    "               mini_batch_size=16,\n",
    "               mini_batch_chunk_size=4, # optionally set this if transformer is too much for your machine\n",
    "               max_epochs=5, # terminate after 5 epochs\n",
    "               embeddings_storage_mode='none',\n",
    "               weight_decay=0.,\n",
    "               scheduler=OneCycleLR,\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6f5e4d",
   "metadata": {},
   "source": [
    "## 2.GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0e706d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3. initialize transformer document embeddings (many models are available)\n",
    "# #flair.device = torch.device('cpu')\n",
    "# document_embeddings = TransformerDocumentEmbeddings('gpt2', fine_tune=True)\n",
    "\n",
    "# # 4. create the text classifier\n",
    "# classifier = TextClassifier(document_embeddings, label_dictionary=label_dict,label_type=label_type)\n",
    "\n",
    "# # 5. initialize the text classifier trainer with Adam optimizer\n",
    "# trainer = ModelTrainer(classifier, corpus, optimizer=torch.optim.AdamW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26cef230",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # 6. start the training\n",
    "# trainer.train('resources_Gpt2/taggers/trec',\n",
    "#                learning_rate=3e-5, # use very small learning rate\n",
    "#                mini_batch_size=4,\n",
    "#                mini_batch_chunk_size=1, # optionally set this if transformer is too much for your machine\n",
    "#                max_epochs=4, \n",
    "#                embeddings_storage_mode='none',\n",
    "#                weight_decay=0.,\n",
    "#                scheduler=OneCycleLR,\n",
    "#                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de59bb1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Predictions with ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "369ef7ac",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-21 10:26:14,734 loading file ./resources_BERT/taggers/trec/best-model.pt\n",
      "2021-12-21 10:26:32,566 loading file ./resources_albert/taggers/trec/best-model.pt\n"
     ]
    }
   ],
   "source": [
    "model1=LinearSVC_pipeline #linear svc\n",
    "model2=TextClassifier.load('./resources_BERT/taggers/trec/best-model.pt')  #bert\n",
    "model3=TextClassifier.load('./resources_albert/taggers/trec/best-model.pt') #albert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ece7d3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "314ae7aa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "prediction_list  = []\n",
    "X_test_acc=X_test[['conv','conv_bigrams_']]\n",
    "for i,row in X_test_acc.iterrows():\n",
    "        #--LinearSVC prediction\n",
    "        model1_class = model1.predict(X_test_acc.loc[[i]])[0]\n",
    "        #Bert Prediction\n",
    "        sentence = Sentence(row['conv'])\n",
    "        model2.predict(sentence)\n",
    "        model2_class = int(sentence.labels[0].value)\n",
    "        #albert Prediction\n",
    "        sentence = Sentence(row['conv'])\n",
    "        model3.predict(sentence)\n",
    "        model3_class = int(sentence.labels[0].value)\n",
    "        pred_class_array = [model1_class,model2_class,model3_class]  #\n",
    "        predicted_occurence_count = Counter(pred_class_array).most_common()\n",
    "        prediction_list.append(predicted_occurence_count[0][0])            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e448fd2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Accuracy of ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8725f781",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9224137931034483\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       184\n",
      "           1       0.83      0.79      0.81        48\n",
      "\n",
      "    accuracy                           0.92       232\n",
      "   macro avg       0.89      0.87      0.88       232\n",
      "weighted avg       0.92      0.92      0.92       232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "X_test['actual'] = y_test\n",
    "X_test['predicted_category'] = prediction_list\n",
    "ensemble_acc=accuracy_score(X_test['actual'], X_test['predicted_category'])\n",
    "print(ensemble_acc)\n",
    "print(metrics.classification_report(y_test, X_test['predicted_category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2860476",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Predicting and saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cbad146c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "prediction_list  = []\n",
    "X_test_acc=dftest[['conv','conv_bigrams_']]\n",
    "for i,row in X_test_acc.iterrows():\n",
    "        #--LinearSVC prediction\n",
    "        model1_class = model1.predict(X_test_acc.loc[[i]])[0]\n",
    "        #Bert Prediction\n",
    "        sentence = Sentence(row['conv'])\n",
    "        model2.predict(sentence)\n",
    "        model2_class = int(sentence.labels[0].value)\n",
    "        #albert Prediction\n",
    "        sentence = Sentence(row['conv'])\n",
    "        model3.predict(sentence)\n",
    "        model3_class = int(sentence.labels[0].value)\n",
    "        pred_class_array = [model1_class,model2_class,model3_class] \n",
    "        predicted_occurence_count = Counter(pred_class_array).most_common()\n",
    "        prediction_list.append(predicted_occurence_count[0][0])            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18680ea8",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "dftest=dftest[['Index']]\n",
    "dftest['Patient_Tag']=prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d390f2ce",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "dftest.to_csv('final_predictions_ensemble.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de08cba7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thank you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640bc11e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6956bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47ec3f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3511617c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89606f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922a6876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c884b653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cb5f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ec060c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ca0095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fa391d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4af30a7",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "command: jupyter nbconvert ZS.ipynb --to slides --post serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bf9203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
